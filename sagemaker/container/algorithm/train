#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import json
import pickle
import sys
import traceback

import pandas as pd

#from sklearn import tree
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_absolute_error, accuracy_score
from sklearn.model_selection import cross_val_score
from numpy import mean

### Impute missing values
from sklearn.preprocessing import Imputer
import numpy as np



# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

#### Data transform

#### Data transform

def preprocess(data):
#    transformed = transform(data)
    transformed = data
    imputed = impute_missing(transformed)
    return imputed

## create dummy variables, and drop initial columns to clean up the dataset
def transform(train):
    train = pd.concat([train, pd.get_dummies(train['Sex'])], axis=1)
    train = pd.concat([train, pd.get_dummies(train['Embarked'],prefix = 'Embarked')], axis=1)
    train = pd.concat([train, pd.get_dummies(train['Cabin'].str[0], prefix='Deck')], axis=1)
    train = train.drop('Sex', axis=1)
    train = train.drop('Embarked', axis=1)
    train = train.drop('Cabin', axis=1)
    train = train.drop('Ticket', axis=1)
    train = train.drop('PassengerId', axis=1)
    train = train.drop('Name',axis=1)
    return train

def impute_missing(df):
    imp = Imputer(missing_values=np.nan, strategy='mean')
    imp.fit(df)
    return pd.DataFrame(imp.transform(df), columns=df.columns)


from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split



def train_and_test(X,y,clf):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    clf.fit(X_train,y_train)
    validation_accuracy = mean(cross_val_score(clf, X_train, y_train, cv=10))
    return clf, clf.score(X_test, y_test), validation_accuracy



def train():
    print('Starting the training.')
    try:
        # Read in any hyperparameters that the user passed with the training job
        with open(param_path, 'r') as tc:
            trainingParams = json.load(tc)

        # Take the set of files and read them all into a single pandas dataframe
        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) if file.endswith('.csv') ]

        if len(input_files) == 0 and ".csv" in input_files:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, channel_name))
        raw_data = [ pd.read_csv(file, engine='python') for file in input_files ]
        train_data = pd.concat(raw_data)

        ####### Create dummy variables and impute missin g data
        t_train = preprocess(train_data)
        X = t_train.drop(['Survived'], axis = 1)
        y = t_train["Survived"]


        #####
        #####  Call the train-and-test function -- it will create a model and run a simple validataion
        #####
        clf = RandomForestRegressor()
        clf, score,validation_accuracy = train_and_test(X,y,clf)

        print('validation-accuracy: ' + str(validation_accuracy))

        # save the model
        with open(os.path.join(model_path, 'logistic-regression.pkl'), 'w') as out:
            pickle.dump(clf, out)
        print('Training complete.')
        print (clf)

    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)
        
        
if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
